{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0268d497",
   "metadata": {},
   "source": [
    "# Tokenization in the Conservative and Interpretive Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872419f",
   "metadata": {},
   "source": [
    "Three differet text versions are provided by the LatEpig scraper.\n",
    "- 'inscription': D(is) M(anibus) [s(acrum)] / Dan[\n",
    "- 'inscription_conservative_cleaning': D M Dan\n",
    "- 'inscription_interpretive_cleaning': Dis Manibus sacrum Dan\n",
    "\n",
    "The 'inscription' contains modern integrations (i.e., [s(acrum)]), resolution of abbreviations (i.e., D(is)), divisions of line (i.e., /), blank within a line (i.e., [3]). For the complete list of special characters used by EDCS see: https://db.edcs.eu/epigr/hinweise/hinweis-en.html. Integrations, resolution of abbreviations, and insertion of missing letters are present in the interpretative cleaning without special characters. The conservative cleaning, instead, does not contain modern integrations on the text and the abbreviations are not resolved. Neither the conservative cleaning nor the interpretive cleaning texts indicate the presence of blanks within a line.\n",
    "\n",
    "Inscriptions do not contain punctuation.\n",
    "\n",
    "The dataset contains 172,958 Latin inscriptions for a total of **1,943,890 tokens** in the **conservative cleaning** texts (that is, the actual tokens present on stone) and 137,341 unique tokens with a mean of 11.2 tokens per inscription.\n",
    "\n",
    "Consider that the frequency of the letter 'M', an abbreviation used for different words (_Manibus, Marcus, merenti_), sums all the occurrences of the letter in the different contexts. Note also that the letter can also be an errant letter being preceded and/or followed by blank spaces on the stone. The 10 most common tokens in the conservative corpus are single letters and 'et' (M: 97,537, D: 67,735, S: 53,357, ET: 53,357, ...). This is due to the fact that funerary texts largely contain abbreviations.\n",
    "\n",
    "The **interpretive texts** contain **2,007,668 tokens** and 115,697 unique words with a mean of 11.6 words per inscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6149596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f851b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "##open the dataset of funerary inscriptions (172,958 rows)\n",
    "Inscriptions = pd.read_csv(\"/Users/u0154817/OneDrive - KU Leuven/Documents/ICLL Prague June 2023/Output/Tituli_Sepulcrales_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86cb581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172958"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Inscriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f9d64",
   "metadata": {},
   "source": [
    "# Conservative cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6ea869",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a list of all the tokens (upper)\n",
    "list_of_tokens_upper = []\n",
    "\n",
    "for i,inscription in enumerate(Inscriptions['inscription_conservative_cleaning']):\n",
    "    inscription = str(inscription)\n",
    "    tokenized_inscription = word_tokenize(inscription) ##tokenize the inscription with NLTK\n",
    "    \n",
    "    for token in tokenized_inscription:\n",
    "        token = token.upper()\n",
    "        list_of_tokens_upper.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6e5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943890"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##number of tokens in the conservative texts (1,943,890)\n",
    "len(list_of_tokens_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba6ab01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137341"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_upper = Counter(list_of_tokens_upper)\n",
    "\n",
    "##number of unique upper tokens (137,341)\n",
    "len(counter_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb3d3ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 97537),\n",
       " ('D', 67735),\n",
       " ('S', 53357),\n",
       " ('ET', 50166),\n",
       " ('L', 43968),\n",
       " ('F', 35649),\n",
       " ('P', 32913),\n",
       " ('V', 31920),\n",
       " ('C', 30192),\n",
       " ('A', 28655)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get the 100 most common tokens \n",
    "most_frequent_tokens_upper = counter_upper.most_common(10)\n",
    "most_frequent_tokens_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3454828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.23908694596376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lenght of tokens per inscription in conservative texts (mean): 11.2\n",
    "import statistics\n",
    "\n",
    "tokens_per_sentence = []\n",
    "\n",
    "for i,inscription in enumerate(Inscriptions['inscription_conservative_cleaning']):    \n",
    "    inscription = str(inscription) ##convert to string\n",
    "    tokenized_inscription = word_tokenize(inscription) ##tokenize the inscription with NLTK\n",
    "    \n",
    "    sum_of_tokens = len(tokenized_inscription) ##calculate the lenght of the list of tokens\n",
    "    tokens_per_sentence.append(sum_of_tokens) ##append the lenght to the tokens_per_sentence\n",
    "    \n",
    "mean = statistics.mean(tokens_per_sentence)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c230ae",
   "metadata": {},
   "source": [
    "# Interpretive cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b298cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a list of all the words in the interpretive texts\n",
    "list_of_words = []\n",
    "\n",
    "for i,inscription in enumerate(Inscriptions['inscription_interpretive_cleaning']):\n",
    "    inscription = str(inscription)\n",
    "    tokenized_inscription = word_tokenize(inscription) ##tokenize the inscription with NLTK\n",
    "    for word in tokenized_inscription:\n",
    "        word = word.lower()\n",
    "        list_of_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fde6202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007668"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##word count in the interpretive texts (2,007,668)\n",
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef628fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_words = Counter(list_of_words)\n",
    "\n",
    "##number of unique words in interpretive texts (115,697)\n",
    "len(counter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41347ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.607835428254258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lenght of words per inscription in interpretive texts (mean): 11.6\n",
    "import statistics\n",
    "\n",
    "tokens_per_sentence = []\n",
    "\n",
    "for i,inscription in enumerate(Inscriptions['inscription_interpretive_cleaning']):    \n",
    "    inscription = str(inscription) ##convert to string\n",
    "    tokenized_inscription = word_tokenize(inscription) ##tokenize the inscription with NLTK\n",
    "    \n",
    "    sum_of_tokens = len(tokenized_inscription) ##calculate the lenght of the list of tokens\n",
    "    tokens_per_sentence.append(sum_of_tokens) ##append the lenght to the tokens_per_sentence\n",
    "    \n",
    "mean = statistics.mean(tokens_per_sentence)\n",
    "mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
